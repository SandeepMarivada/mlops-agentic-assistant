# ── CI/CD Pipeline: MLOps Agentic AI → AWS EC2 ───────────────────────────────
# Build Docker images on GitHub runner (fast), push to ghcr.io,
# then EC2 just pulls and runs — no building on EC2.
#
# Required GitHub Secrets:
#   EC2_HOST           — public IP or DNS of your EC2 instance
#   EC2_USERNAME       — usually "ubuntu"
#   EC2_SSH_KEY        — contents of your .pem private key file
#   OPENROUTER_API_KEY — written to .env on EC2

name: CI/CD Pipeline — EC2 Deploy

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:

  # ── Job 1: Build images on runner, push to GitHub Container Registry ─────────
  build:
    name: Build & Push Docker Images
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push API image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: Dockerfile.api
          push: true
          tags: ghcr.io/${{ github.repository_owner }}/mlops-api:latest

      - name: Build and push UI image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: Dockerfile.ui
          push: true
          tags: ghcr.io/${{ github.repository_owner }}/mlops-ui:latest


  # ── Job 2: Pull pre-built images on EC2 and start containers ─────────────────
  deploy:
    name: Deploy to AWS EC2
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    steps:
      - name: Deploy to EC2 via SSH
        uses: appleboy/ssh-action@v1.0.3
        env:
          GHCR_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO_OWNER: ${{ github.repository_owner }}
          OPENROUTER_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USERNAME }}
          key: ${{ secrets.EC2_SSH_KEY }}
          envs: GHCR_TOKEN,REPO_OWNER,OPENROUTER_KEY
          command_timeout: 15m
          script: |
            set -e

            echo "──────────────────────────────────────"
            echo "Deploying MLOps Agentic AI"
            echo "──────────────────────────────────────"

            # GHCR image names must be lowercase
            OWNER=$(echo "$REPO_OWNER" | tr '[:upper:]' '[:lower:]')

            # Login to GitHub Container Registry
            echo "$GHCR_TOKEN" | docker login ghcr.io -u "$OWNER" --password-stdin

            # Clone repo on first deploy, pull on subsequent (for docker-compose.yml + data/)
            if [ ! -d "/app/mlops-agentic-ai" ]; then
              echo "First deploy — cloning repo..."
              mkdir -p /app
              git clone https://github.com/SandeepMarivada/mlops-agentic-assistant.git /app/mlops-agentic-ai
            else
              echo "Pulling latest code..."
              cd /app/mlops-agentic-ai && git pull origin main
            fi

            cd /app/mlops-agentic-ai

            # Write .env file from GitHub secrets
            echo "OPENROUTER_API_KEY=$OPENROUTER_KEY" > .env
            echo "MODEL_NAME=openai/gpt-4o-mini" >> .env

            # Stop existing containers
            docker compose down --remove-orphans || true

            # Pull pre-built images from GitHub Container Registry
            echo "Pulling images built on GitHub runner..."
            docker pull ghcr.io/$OWNER/mlops-api:latest
            docker pull ghcr.io/$OWNER/mlops-ui:latest

            # Start containers (no --build, uses pulled images)
            docker compose up -d

            sleep 10
            docker compose ps

            echo "──────────────────────────────────────"
            echo "Deployment complete!"
            echo "──────────────────────────────────────"
